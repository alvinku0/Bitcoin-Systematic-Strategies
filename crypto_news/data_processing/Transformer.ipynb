{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b39678",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas tensorflow sklearn matplotlib math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac55de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D, LayerNormalization, MultiHeadAttention\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import math\n",
    "\n",
    "# Positional encoding function\n",
    "def positional_encoding(seq_length, d_model):\n",
    "    \"\"\"Create standard transformer positional encoding\"\"\"\n",
    "    positions = np.arange(seq_length)[:, np.newaxis]\n",
    "    angles = np.arange(d_model)[np.newaxis, :] / np.power(10000, 2 * (np.arange(d_model)[np.newaxis, :] // 2) / d_model)\n",
    "    \n",
    "    pos_encoding = np.zeros((seq_length, d_model))\n",
    "    pos_encoding[:, 0::2] = np.sin(positions * angles[:, 0::2])\n",
    "    pos_encoding[:, 1::2] = np.cos(positions * angles[:, 1::2])\n",
    "    \n",
    "    return tf.cast(pos_encoding[np.newaxis, ...], tf.float32)\n",
    "\n",
    "# Create sequences for time series data\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    \n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Data preparation function\n",
    "def prepare_data(price_data, target_col='return_forward', seq_length=24, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Prepare data for transformer model training\n",
    "    \"\"\"\n",
    "    # Drop rows with NaN values\n",
    "    price_data = price_data.dropna()\n",
    "    \n",
    "    # Separate features and target\n",
    "    y = price_data[target_col].values\n",
    "    X = price_data.drop(columns=[target_col])\n",
    "    \n",
    "    # Save feature names for later\n",
    "    feature_names = X.columns.tolist()\n",
    "    X = X.values\n",
    "    \n",
    "    # Create sequences\n",
    "    X_seq, y_seq = create_sequences(X, y, seq_length)\n",
    "    \n",
    "    # Split into train and test\n",
    "    train_size = int(len(X_seq) * (1 - test_size))\n",
    "    X_train, X_test = X_seq[:train_size], X_seq[train_size:]\n",
    "    y_train, y_test = y_seq[:train_size], y_seq[train_size:]\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    n_samples, n_timesteps, n_features = X_train.shape\n",
    "    X_train_reshaped = X_train.reshape(n_samples * n_timesteps, n_features)\n",
    "    X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
    "    X_train = X_train_scaled.reshape(n_samples, n_timesteps, n_features)\n",
    "    \n",
    "    # Scale test data\n",
    "    n_samples, n_timesteps, n_features = X_test.shape\n",
    "    X_test_reshaped = X_test.reshape(n_samples * n_timesteps, n_features)\n",
    "    X_test_scaled = scaler.transform(X_test_reshaped)\n",
    "    X_test = X_test_scaled.reshape(n_samples, n_timesteps, n_features)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler, feature_names\n",
    "\n",
    "# Build transformer model\n",
    "def build_transformer_model(seq_length, n_features, n_heads=4, d_model=64, dff=128, n_layers=2, dropout_rate=0.1):\n",
    "    \"\"\"\n",
    "    Build a transformer model for time series prediction\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "    \n",
    "    # Add positional encoding\n",
    "    pos_encoding = positional_encoding(seq_length, n_features)\n",
    "    x = inputs + pos_encoding\n",
    "    \n",
    "    # Transformer blocks\n",
    "    for _ in range(n_layers):\n",
    "        # Multi-head attention\n",
    "        attention_output = MultiHeadAttention(\n",
    "            num_heads=n_heads, key_dim=d_model//n_heads\n",
    "        )(x, x)\n",
    "        attention_output = Dropout(dropout_rate)(attention_output)\n",
    "        \n",
    "        # Add & Norm\n",
    "        x = LayerNormalization(epsilon=1e-6)(x + attention_output)\n",
    "        \n",
    "        # Feed Forward Network\n",
    "        ffn_output = Dense(dff, activation='relu')(x)\n",
    "        ffn_output = Dense(n_features)(ffn_output)\n",
    "        ffn_output = Dropout(dropout_rate)(ffn_output)\n",
    "        \n",
    "        # Add & Norm\n",
    "        x = LayerNormalization(epsilon=1e-6)(x + ffn_output)\n",
    "    \n",
    "    # Global pooling\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Final dense layers\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "def train_transformer_model(X_train, y_train, X_test, y_test, seq_length, n_features, \n",
    "                           epochs=100, batch_size=32, patience=20):\n",
    "    \"\"\"\n",
    "    Train the transformer model and evaluate\n",
    "    \"\"\"\n",
    "    # Build model\n",
    "    model = build_transformer_model(seq_length, n_features)\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        'transformer_model_best.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping, model_checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_rmse = math.sqrt(mean_squared_error(y_train, train_preds))\n",
    "    test_rmse = math.sqrt(mean_squared_error(y_test, test_preds))\n",
    "    train_mae = mean_absolute_error(y_train, train_preds)\n",
    "    test_mae = mean_absolute_error(y_test, test_preds)\n",
    "    train_r2 = r2_score(y_train, train_preds)\n",
    "    test_r2 = r2_score(y_test, test_preds)\n",
    "    \n",
    "    print(f'Train RMSE: {train_rmse:.4f}')\n",
    "    print(f'Test RMSE: {test_rmse:.4f}')\n",
    "    print(f'Train MAE: {train_mae:.4f}')\n",
    "    print(f'Test MAE: {test_mae:.4f}')\n",
    "    print(f'Train R²: {train_r2:.4f}')\n",
    "    print(f'Test R²: {test_r2:.4f}')\n",
    "    \n",
    "    return model, history, train_preds, test_preds\n",
    "\n",
    "# Plot results \n",
    "def plot_results(history, y_train, train_preds, y_test, test_preds):\n",
    "    \"\"\"Plot training history and predictions\"\"\"\n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    \n",
    "    # Plot 1: Training and Validation Loss\n",
    "    axs[0, 0].plot(history.history['loss'], label='Training Loss')\n",
    "    axs[0, 0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    axs[0, 0].set_title('Model Loss')\n",
    "    axs[0, 0].set_xlabel('Epoch')\n",
    "    axs[0, 0].set_ylabel('Loss (MSE)')\n",
    "    axs[0, 0].legend(loc='upper right')\n",
    "    axs[0, 0].grid(True)\n",
    "    \n",
    "    # Plot 2: Training Set Predictions\n",
    "    axs[0, 1].plot(y_train, label='Actual Values', color='blue', alpha=0.6)\n",
    "    axs[0, 1].plot(train_preds, label='Predicted Values', color='red', alpha=0.6)\n",
    "    axs[0, 1].set_title('Training Set: Actual vs Predicted')\n",
    "    axs[0, 1].set_xlabel('Time Step')\n",
    "    axs[0, 1].set_ylabel('Value')\n",
    "    axs[0, 1].legend(loc='upper right')\n",
    "    axs[0, 1].grid(True)\n",
    "    \n",
    "    # Plot 3: Test Set Predictions\n",
    "    axs[1, 0].plot(y_test, label='Actual Values', color='blue', alpha=0.6)\n",
    "    axs[1, 0].plot(test_preds, label='Predicted Values', color='red', alpha=0.6)\n",
    "    axs[1, 0].set_title('Test Set: Actual vs Predicted')\n",
    "    axs[1, 0].set_xlabel('Time Step')\n",
    "    axs[1, 0].set_ylabel('Value')\n",
    "    axs[1, 0].legend(loc='upper right')\n",
    "    axs[1, 0].grid(True)\n",
    "    \n",
    "    # Plot 4: Actual vs Predicted Scatter Plot (Test Set)\n",
    "    axs[1, 1].scatter(y_test, test_preds, alpha=0.5)\n",
    "    axs[1, 1].plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)\n",
    "    axs[1, 1].set_title('Test Set: Actual vs Predicted Scatter Plot')\n",
    "    axs[1, 1].set_xlabel('Actual Values')\n",
    "    axs[1, 1].set_ylabel('Predicted Values')\n",
    "    axs[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('transformer_model_results.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Generate trading signals from model predictions\n",
    "def generate_signals(model, X_data, threshold=0.0):\n",
    "    \"\"\"\n",
    "    Generate trading signals from model predictions\n",
    "    1 for buy (predicted return > threshold)\n",
    "    0 for hold (predicted return = threshold)\n",
    "    -1 for sell (predicted return < threshold)\n",
    "    \"\"\"\n",
    "    predictions = model.predict(X_data)\n",
    "    signals = np.where(predictions > threshold, 1, np.where(predictions < -threshold, -1, 0))\n",
    "    return signals.flatten()\n",
    "\n",
    "# Main execution function for transformer model\n",
    "def run_transformer_prediction(price_data, target_col='return_forward', seq_length=24, \n",
    "                              test_size=0.2, epochs=100, batch_size=32):\n",
    "    \"\"\"\n",
    "    Complete end-to-end transformer model pipeline\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    X_train, X_test, y_train, y_test, scaler, feature_names = prepare_data(\n",
    "        price_data, target_col, seq_length, test_size\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    model, history, train_preds, test_preds = train_transformer_model(\n",
    "        X_train, y_train, X_test, y_test, seq_length, len(feature_names),\n",
    "        epochs, batch_size\n",
    "    )\n",
    "    \n",
    "    # Plot results\n",
    "    plot_results(history, y_train, train_preds, y_test, test_preds)\n",
    "    \n",
    "    # Generate signals for backtest\n",
    "    test_signals = generate_signals(model, X_test)\n",
    "    \n",
    "    return model, history, train_preds, test_preds, test_signals\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    price_indicator = pd.read_parquet(\"/workspaces/fyp/bitcoin_historical_price/btcusd_hourly_price_indicators.parquet\")\n",
    "    \n",
    "    # Run transformer prediction\n",
    "    model, history, train_preds, test_preds, test_signals = run_transformer_prediction(\n",
    "        price_indicator,\n",
    "        target_col='return_forward',\n",
    "        seq_length=24,  # 24 hours of data\n",
    "        test_size=0.2,\n",
    "        epochs=100,\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    # For backtesting (assuming data aligns correctly)\n",
    "    # We'd need to create a dataframe with the signals and pass it to run_backtest\n",
    "    # This is a simplified example - you'd need to match the test signals with the correct dates\n",
    "    test_indices = price_indicator.index[-len(test_signals):]\n",
    "    backtest_df = pd.DataFrame({\n",
    "        'signal': test_signals\n",
    "    }, index=test_indices)\n",
    "    \n",
    "    # Run backtest (if the backtest function is available)\n",
    "    # run_backtest(backtest_df, freq='h')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
