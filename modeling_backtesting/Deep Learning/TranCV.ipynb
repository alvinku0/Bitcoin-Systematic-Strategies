{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e2ea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /home/codespace/.local/lib/python3.12/site-packages (19.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b22f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd786dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/full_dataset_feature_engineering_v2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92333629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 05:15:30.055085: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-21 05:15:30.264566: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-21 05:15:30.355602: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745212530.468935   22074 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745212530.508195   22074 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745212530.785423   22074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745212530.785455   22074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745212530.785458   22074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745212530.785460   22074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-21 05:15:30.818656: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the scalers and feature list\n",
    "with open('./pickles/hybrid_feature_scaler.pkl', 'rb') as file:\n",
    "    feature_scaler = pickle.load(file)\n",
    "\n",
    "with open('./pickles/hybrid_target_scaler.pkl', 'rb') as file:\n",
    "    target_scaler = pickle.load(file)\n",
    "\n",
    "with open('./pickles/hybrid_selected_features.pkl', 'rb') as file:\n",
    "    selected_features = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52c501e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (35046, 12, 15)\n",
      "y shape: (35046, 1)\n",
      "Total sequences: 35046\n",
      "Training sequences: 26262\n",
      "Testing sequences: 8784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_df = df[selected_features].values\n",
    "y_df = df['return_forward'].values  # Replace with your target column name\n",
    "original_indexes = df.index.tolist()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_df)\n",
    "\n",
    "# If your target needs scaling too (for regression problems)\n",
    "y_scaler = MinMaxScaler()\n",
    "y_scaled = y_scaler.fit_transform(y_df.reshape(-1, 1))\n",
    "\n",
    "# Define sequence length (time steps to look back)\n",
    "sequence_length = 12  # Adjust based on your specific problem\n",
    "\n",
    "# Create sequences for transformer\n",
    "X_sequences = []\n",
    "y_sequences = []\n",
    "sequence_indexes = []\n",
    "\n",
    "for i in range(len(X_scaled) - sequence_length):\n",
    "    X_sequences.append(X_scaled[i:i+sequence_length])\n",
    "    y_sequences.append(y_scaled[i+sequence_length])\n",
    "    sequence_indexes.append(original_indexes[i+sequence_length])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_sequences = np.array(X_sequences)\n",
    "y_sequences = np.array(y_sequences)\n",
    "\n",
    "# Check the resulting shapes\n",
    "print(f\"X shape: {X_sequences.shape}\")  # Should be (samples, sequence_length, num_features)\n",
    "print(f\"y shape: {y_sequences.shape}\")  # Should be (samples, 1) or (samples,)\n",
    "\n",
    "# Split into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test ,train_idx, test_idx = train_test_split(\n",
    "    X_sequences, y_sequences, sequence_indexes, test_size=0.25062, shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Total sequences: {len(sequence_indexes)}\")\n",
    "print(f\"Training sequences: {len(train_idx)}\")\n",
    "print(f\"Testing sequences: {len(test_idx)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298f2d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Transformer Tuning ---\n",
      "Input shape: (Timesteps=12, Features=15)\n",
      "Tuning Params: d_model, num_encoder_layers, num_heads\n",
      "Fixed Params: LR=0.005, Batch=32, Dropout=0.1, FF_Factor=4, Act=relu\n",
      "Search: 5 iterations, 2 folds\n",
      "------------------------------\n",
      "Fitting RandomizedSearchCV...\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 05:15:35.887757: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-04-21 05:15:36.563482: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-04-21 05:15:47.889869: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-04-21 05:25:51.741829: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, model__d_model=64, model__num_encoder_layers=3, model__num_heads=4; total time=10.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 05:26:06.190761: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-04-21 05:36:03.601274: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, model__d_model=64, model__num_encoder_layers=3, model__num_heads=4; total time=10.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 05:36:14.687584: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-04-21 05:43:36.847503: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, model__d_model=64, model__num_encoder_layers=2, model__num_heads=4; total time= 7.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 05:43:47.942595: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-04-21 05:52:39.051803: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, model__d_model=64, model__num_encoder_layers=2, model__num_heads=4; total time= 9.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 05:52:54.908977: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-04-21 06:05:31.940613: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, model__d_model=64, model__num_encoder_layers=3, model__num_heads=4; total time=12.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 06:05:47.543204: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-04-21 06:20:14.361334: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, model__d_model=64, model__num_encoder_layers=3, model__num_heads=4; total time=14.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 06:20:29.330645: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-04-21 06:29:42.736308: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, model__d_model=64, model__num_encoder_layers=2, model__num_heads=4; total time= 9.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 06:29:53.335069: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-04-21 06:37:43.551045: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, model__d_model=64, model__num_encoder_layers=2, model__num_heads=4; total time= 8.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 06:37:58.002083: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-04-21 06:50:11.526699: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, model__d_model=64, model__num_encoder_layers=3, model__num_heads=4; total time=12.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 06:50:27.239660: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n",
      "2025-04-21 07:02:58.327693: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, model__d_model=64, model__num_encoder_layers=3, model__num_heads=4; total time=12.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 07:03:21.276903: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Randomized Search Finished.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_PredictScorer' object has no attribute '__name__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 266\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# --- Process Results ---\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m search_results:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBest Score (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43msearch_results\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer_\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch_results.best_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    267\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest Parameters Found:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    268\u001b[39m     best_params_display = {k.replace(\u001b[33m'\u001b[39m\u001b[33mmodel__\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m): v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m search_results.best_params_.items()}\n",
      "\u001b[31mAttributeError\u001b[39m: '_PredictScorer' object has no attribute '__name__'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers # Required for Transformer components\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Use scikeras wrapper for Regressor\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, loguniform # For parameter distributions if needed later\n",
    "\n",
    "# --- Ensure Transformer Components are Defined or Imported ---\n",
    "# (Assuming positional_encoding and TransformerEncoderBlock are defined as before)\n",
    "# Helper function for Positional Encoding\n",
    "def positional_encoding(length, depth):\n",
    "    # (Implementation from previous example)\n",
    "    depth = depth / 2\n",
    "    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "    angle_rates = 1 / (10000**depths)                # (1, depth)\n",
    "    angle_rads = positions * angle_rates             # (pos, depth)\n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis=-1)\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)[tf.newaxis, :, :]\n",
    "\n",
    "# Transformer Encoder Block Layer\n",
    "class TransformerEncoderBlock(layers.Layer):\n",
    "    # (Implementation from previous example, including get_config)\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout_rate=0.1, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.activation = activation\n",
    "        if d_model % num_heads != 0:\n",
    "             raise ValueError(f\"d_model ({d_model}) must be divisible by num_heads ({num_heads})\")\n",
    "        self.key_dim = d_model // num_heads\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=self.key_dim, dropout=dropout_rate)\n",
    "        self.ffn = keras.Sequential([layers.Dense(ff_dim, activation=activation), layers.Dense(d_model)])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'d_model': self.d_model, 'num_heads': self.num_heads, 'ff_dim': self.ff_dim,\n",
    "                       'dropout_rate': self.dropout_rate, 'activation': self.activation})\n",
    "        return config\n",
    "\n",
    "# --- Ensure Transformer Model Creation Function is Defined or Imported ---\n",
    "# (Assuming create_transformer_model is defined as before)\n",
    "def create_transformer_model(\n",
    "    d_model=128, num_heads=8, num_encoder_layers=4, learning_rate=0.001,\n",
    "    n_timesteps=20, n_features=5, ff_dim_factor=4, dropout_rate=0.1,\n",
    "    activation='relu', optimizer_name='adam', loss_function='mean_squared_error'\n",
    "    ):\n",
    "    # (Implementation from previous example)\n",
    "    ff_dim = d_model * ff_dim_factor\n",
    "    inputs = keras.Input(shape=(n_timesteps, n_features))\n",
    "    x = layers.TimeDistributed(layers.Dense(d_model))(inputs)\n",
    "    pos_enc = positional_encoding(length=n_timesteps, depth=d_model)\n",
    "    x += pos_enc[:, :n_timesteps, :]\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    for _ in range(num_encoder_layers):\n",
    "        encoder_block = TransformerEncoderBlock(d_model=d_model, num_heads=num_heads, ff_dim=ff_dim,\n",
    "                                                dropout_rate=dropout_rate, activation=activation)\n",
    "        x = encoder_block(x)\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_last\")(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(1, activation=\"linear\", dtype='float32')(x) # Ensure output is float32 for mixed precision\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=f\"Transformer_Reg\")\n",
    "    if optimizer_name.lower() == 'adam': optimizer = Adam(learning_rate=learning_rate)\n",
    "    else: optimizer = Adam(learning_rate=learning_rate) # Defaulting to Adam\n",
    "    model.compile(loss=loss_function, optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- Function to Perform Randomized Search for Key Transformer Hyperparameters ---\n",
    "\n",
    "def tune_transformer_hyperparameters(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    n_iter: int = 5,\n",
    "    cv: int = 2,\n",
    "    # --- Define search ranges for the 3 key parameters ---\n",
    "    d_model_options: list = [64, 128, 256],\n",
    "    num_heads_options: list = [4, 8], # Ensure compatibility with d_model options\n",
    "    num_layers_range: tuple = (2, 7), # Min layers (inclusive), Max layers (exclusive)\n",
    "    # --- Specify Fixed Parameters for this tuning run ---\n",
    "    fixed_learning_rate: float = 0.001,\n",
    "    fixed_batch_size: int = 64, # Can be tuned separately or fixed\n",
    "    fixed_ff_dim_factor: int = 4,\n",
    "    fixed_dropout_rate: float = 0.1,\n",
    "    fixed_activation: str = 'relu',\n",
    "    fixed_epochs: int = 100,\n",
    "    early_stopping_patience: int = 10,\n",
    "    scoring_metric: str = 'neg_mean_squared_error', # For regression\n",
    "    random_state: int = 42\n",
    "    ) -> RandomizedSearchCV:\n",
    "    \"\"\"\n",
    "    Performs RandomizedSearchCV for a Transformer regression model, focusing on\n",
    "    d_model, num_encoder_layers, and num_heads.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training features (samples, timesteps, features).\n",
    "        y_train: Training target values.\n",
    "        n_iter: Number of parameter settings sampled by RandomizedSearchCV.\n",
    "        cv: Number of cross-validation folds.\n",
    "        d_model_options: List of choices for model dimensionality.\n",
    "        num_heads_options: List of choices for attention heads.\n",
    "        num_layers_range: Tuple (min, max) for randint sampling of encoder layers.\n",
    "        fixed_learning_rate: Learning rate to use (fixed for this search).\n",
    "        fixed_batch_size: Batch size to use (fixed for this search).\n",
    "        fixed_ff_dim_factor: Factor to determine feedforward dim (d_model * factor).\n",
    "        fixed_dropout_rate: Dropout rate to use.\n",
    "        fixed_activation: Activation function ('relu' or 'gelu').\n",
    "        fixed_epochs: Max epochs for training each model (used with EarlyStopping).\n",
    "        early_stopping_patience: Patience for EarlyStopping callback.\n",
    "        scoring_metric: Scikit-learn scorer name for evaluation.\n",
    "        random_state: Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        Fitted RandomizedSearchCV object containing the results.\n",
    "    \"\"\"\n",
    "    tf.random.set_seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Derive input shapes from data\n",
    "    if X_train.ndim != 3:\n",
    "        raise ValueError(\"X_train must be 3-dimensional (samples, timesteps, features)\")\n",
    "    n_timesteps = X_train.shape[1]\n",
    "    n_features = X_train.shape[2]\n",
    "\n",
    "    print(f\"--- Starting Transformer Tuning ---\")\n",
    "    print(f\"Input shape: (Timesteps={n_timesteps}, Features={n_features})\")\n",
    "    print(f\"Tuning Params: d_model, num_encoder_layers, num_heads\")\n",
    "    print(f\"Fixed Params: LR={fixed_learning_rate}, Batch={fixed_batch_size}, \"\n",
    "          f\"Dropout={fixed_dropout_rate}, FF_Factor={fixed_ff_dim_factor}, Act={fixed_activation}\")\n",
    "    print(f\"Search: {n_iter} iterations, {cv} folds\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # --- Define Hyperparameter Search Space ---\n",
    "    param_distributions = {\n",
    "        # Tuned Model Hyperparameters\n",
    "        'model__d_model': d_model_options,\n",
    "        'model__num_heads': num_heads_options,\n",
    "        'model__num_encoder_layers': randint(num_layers_range[0], num_layers_range[1]),\n",
    "\n",
    "        # Fixed Model Hyperparameters (passed directly to the estimator)\n",
    "        # Note: These are set in KerasRegressor below, not sampled here.\n",
    "\n",
    "        # Fixed Training Hyperparameters (passed directly to the estimator)\n",
    "        'batch_size': [fixed_batch_size] # Needs to be a list for RandomizedSearchCV, even if fixed\n",
    "    }\n",
    "\n",
    "    # --- Set up KerasRegressor ---\n",
    "    keras_regressor = KerasRegressor(\n",
    "        model=create_transformer_model,\n",
    "        # Pass fixed model parameters required by create_transformer_model\n",
    "        model__n_timesteps=n_timesteps,\n",
    "        model__n_features=n_features,\n",
    "        model__learning_rate=fixed_learning_rate, # Fixed LR\n",
    "        model__ff_dim_factor=fixed_ff_dim_factor,\n",
    "        model__dropout_rate=fixed_dropout_rate,\n",
    "        model__activation=fixed_activation,\n",
    "        model__loss_function='mean_squared_error', # Assuming MSE loss\n",
    "        # Pass other fixed wrapper/compile params\n",
    "        loss='mean_squared_error',\n",
    "        optimizer='adam', # Optimizer type fixed here\n",
    "        metrics=['mae', 'mse'],\n",
    "        # Pass fixed fit parameters\n",
    "        epochs=fixed_epochs,\n",
    "        # Other fixed settings\n",
    "        random_state=random_state,\n",
    "        verbose=0 # Suppress Keras fit logs during search\n",
    "    )\n",
    "\n",
    "    # --- Define Callbacks ---\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=early_stopping_patience,\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # --- Setup Randomized Search CV ---\n",
    "    random_search_transformer = RandomizedSearchCV(\n",
    "        estimator=keras_regressor,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        scoring=scoring_metric,\n",
    "        verbose=2, # Show progress during search\n",
    "        n_jobs=1, # Safer for GPU memory management\n",
    "        random_state=random_state,\n",
    "        error_score='raise' # See errors during fitting\n",
    "    )\n",
    "\n",
    "    # --- Run the Search ---\n",
    "    try:\n",
    "        print(\"Fitting RandomizedSearchCV...\")\n",
    "        search_result = random_search_transformer.fit(\n",
    "            X_train, y_train,\n",
    "            callbacks=[early_stopping],\n",
    "            validation_split=0.2 # Use portion of training data in each fold for early stopping\n",
    "        )\n",
    "        print(\"\\nRandomized Search Finished.\")\n",
    "        return search_result\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nAn error occurred during Randomized Search, potentially related to incompatible d_model/num_heads.\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        print(\"Consider adjusting d_model_options and num_heads_options.\")\n",
    "        return None # Indicate failure\n",
    "\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == '__main__':\n",
    "    # Generate dummy data for demonstration\n",
    "    N_SAMPLES_DEMO = 500\n",
    "    N_TIMESTEPS_DEMO = 20\n",
    "    N_FEATURES_DEMO = 5\n",
    "\n",
    "    def generate_regression_data(n_samples, n_timesteps, n_features):\n",
    "        X = np.random.rand(n_samples, n_timesteps, n_features)\n",
    "        y = np.sum(X[:, :, 0], axis=1) * 2.5 + np.random.normal(0, 0.5, n_samples)\n",
    "        return X, y\n",
    "\n",
    "    # X_demo, y_demo = generate_regression_data(N_SAMPLES_DEMO, N_TIMESTEPS_DEMO, N_FEATURES_DEMO)\n",
    "    # # In a real scenario, you'd use your actual train/test split\n",
    "    # # X_train_real, _, y_train_real, _ = train_test_split(...)\n",
    "\n",
    "    # print(f\"Demo Data Shapes: X={X_demo.shape}, y={y_demo.shape}\")\n",
    "\n",
    "    # --- Call the tuning function ---\n",
    "    # Reduce n_iter for quick demo\n",
    "    search_results = tune_transformer_hyperparameters(\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        n_iter=5, # Reduced for speed in demo\n",
    "        cv=2,      # Reduced for speed in demo\n",
    "        d_model_options=[64, 128],       # Example options\n",
    "        num_heads_options=[4,8],           # Example options (ensure compatibility)\n",
    "        num_layers_range=(2, 4),         # Example range (2 or 3 layers)\n",
    "        fixed_learning_rate=0.005,       # Example fixed LR\n",
    "        fixed_batch_size=32,\n",
    "        random_state=42 # Assuming SEED is defined (e.g., SEED=42)\n",
    "    )\n",
    "\n",
    "    # --- Process Results ---\n",
    "    if search_results:\n",
    "        print(f\"\\nBest Score ({search_results.scorer_.__name__}): {search_results.best_score_:.4f}\")\n",
    "        print(\"Best Parameters Found:\")\n",
    "        best_params_display = {k.replace('model__', ''): v for k, v in search_results.best_params_.items()}\n",
    "        print(best_params_display)\n",
    "\n",
    "        # You can access the best model refitted on the full training data (used in tuning)\n",
    "        # best_model = search_results.best_estimator_\n",
    "        # performance = best_model.evaluate(X_test, y_test) # Evaluate on actual test set\n",
    "        # print(f\"Test performance of best model: {performance}\")\n",
    "    else:\n",
    "        print(\"\\nHyperparameter tuning failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2b1846f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=2, error_score='raise',\n",
      "                   estimator=KerasRegressor(epochs=100, loss='mean_squared_error', metrics=['mae', 'mse'], model=<function create_transformer_model at 0x7ed487f0c680>, model__activation='relu', model__dropout_rate=0.1, model__ff_dim_factor=4, model__learning_rate=0.005, model__loss_function='mean_squared_error', model__n_features=15, model__n_timesteps=12, optimizer='adam', random_state=42, verbose=0),\n",
      "                   n_iter=5, n_jobs=1,\n",
      "                   param_distributions={'batch_size': [32],\n",
      "                                        'model__d_model': [64, 128],\n",
      "                                        'model__num_encoder_layers': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7ed489077a40>,\n",
      "                                        'model__num_heads': [4]},\n",
      "                   random_state=42, scoring='neg_mean_squared_error',\n",
      "                   verbose=2)\n"
     ]
    }
   ],
   "source": [
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "276466b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'model__d_model': 64, 'model__num_encoder_layers': 3, 'model__num_heads': 4}\n"
     ]
    }
   ],
   "source": [
    "print(search_results.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
